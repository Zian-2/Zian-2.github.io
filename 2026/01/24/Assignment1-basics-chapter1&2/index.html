<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/green/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous" defer></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.27.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":true,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="本文为cs336的assignment1中分词器对应章节的参考解答和课程笔记。    1 本文范围内的作业暂时还不需要用到GPU2 本课程并未提供好系统适配，所以事实上不推荐在win上完成作业。在你的服务器or虚拟机上完成可以避免很多麻烦。 Setup：环境配置：按照https:&#x2F;&#x2F;github.com&#x2F;stanford-cs336&#x2F;assignment1-basics&#x2F;tree&#x2F;main 中RE">
<meta property="og:type" content="article">
<meta property="og:title" content="cs336：Assignment1-basics-chapter1&amp;2">
<meta property="og:url" content="http://example.com/2026/01/24/Assignment1-basics-chapter1&2/index.html">
<meta property="og:site_name" content="Homepage">
<meta property="og:description" content="本文为cs336的assignment1中分词器对应章节的参考解答和课程笔记。    1 本文范围内的作业暂时还不需要用到GPU2 本课程并未提供好系统适配，所以事实上不推荐在win上完成作业。在你的服务器or虚拟机上完成可以避免很多麻烦。 Setup：环境配置：按照https:&#x2F;&#x2F;github.com&#x2F;stanford-cs336&#x2F;assignment1-basics&#x2F;tree&#x2F;main 中RE">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2026-01-24T14:15:15.000Z">
<meta property="article:modified_time" content="2026-02-02T12:18:17.939Z">
<meta property="article:author" content="Zian Wang">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="cs336">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/2026/01/24/Assignment1-basics-chapter1&2/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2026/01/24/Assignment1-basics-chapter1&2/","path":"2026/01/24/Assignment1-basics-chapter1&2/","title":"cs336：Assignment1-basics-chapter1&2"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>cs336：Assignment1-basics-chapter1&2 | Homepage</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script><script src="/js/pjax.js" defer></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.5.0/search.js" integrity="sha256-xFC6PJ82SL9b3WkGjFavNiA9gm5z6UBxWPiu4CYjptg=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>





  <script src="/js/third-party/pace.js" defer></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"cdn":"//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML","tags":"ams","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js" defer></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<script>
  // 无论谁抢了焦点，一律滚回顶端
  (function() {
    // 立即执行：禁止浏览器恢复滚动
    if ('scrollRestoration' in history) { history.scrollRestoration = 'manual'; }
    
    // 页面加载完成后 100 毫秒，强行归位
    window.addEventListener('load', function() {
      setTimeout(function() {
        window.scrollTo(0, 0);
        document.body.scrollTop = 0;
      }, 100);
    });
  })();
</script>


<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  
  <video id="custom-bg-video" autoplay loop muted playsinline tabindex="-1">
    <source src="/images/background.mp4" type="video/mp4">
  </video>

  <div class="headband"></div>
  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Homepage</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="Searching..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Setup%EF%BC%9A"><span class="nav-text">Setup：</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%EF%BC%9A"><span class="nav-text">环境配置：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E4%B8%8B%E8%BD%BD%EF%BC%9A"><span class="nav-text">数据下载：</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-%E4%BD%9C%E4%B8%9A%E6%80%BB%E8%A7%88"><span class="nav-text">1 作业总览</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%A0%E5%B0%86%E5%AE%9E%E7%8E%B0%EF%BC%9A"><span class="nav-text">你将实现：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%A0%E5%B0%86%E5%AE%8C%E6%88%90%E5%A6%82%E4%B8%8B%E4%BB%BB%E5%8A%A1%EF%BC%9A"><span class="nav-text">你将完成如下任务：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%81%E8%AE%B8%E4%BD%BF%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%EF%BC%9A"><span class="nav-text">允许使用的工具：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B3%E4%BA%8E-AI-%E5%B7%A5%E5%85%B7%EF%BC%9A"><span class="nav-text">关于 AI 工具：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E8%8E%B7%E5%8F%96%EF%BC%9A"><span class="nav-text">数据集获取：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%99%8D%E4%BD%8E%E8%A7%84%E6%A8%A1%E7%9A%84%E5%BB%BA%E8%AE%AE%EF%BC%9A"><span class="nav-text">降低规模的建议：</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-BPE-Byte-Pair-Encoding-%E5%88%86%E8%AF%8D%E5%99%A8"><span class="nav-text">2 BPE(Byte-Pair Encoding)分词器</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-unicode%E6%A0%87%E5%87%86"><span class="nav-text">2.1 unicode标准</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Problem-unicode1-unicode%E4%BB%8B%E7%BB%8D-%EF%BC%881%E5%88%86%EF%BC%89"><span class="nav-text">Problem (unicode1): unicode介绍 （1分）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-unicode%E7%BC%96%E7%A0%81"><span class="nav-text">2.2 unicode编码</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%BE%E7%A8%8B%E6%96%87%E6%A1%A3%E5%A4%96%E7%9A%84%E8%A1%A5%E5%85%85%EF%BC%9AUTF-8%E5%AD%97%E8%8A%82%E5%BA%8F%E5%88%97%E5%AF%B9%E5%BA%94%E8%A7%84%E5%88%99"><span class="nav-text">课程文档外的补充：UTF-8字节序列对应规则</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Problem-unicode2-unicode%E7%BC%96%E7%A0%81%EF%BC%883%E5%88%86%EF%BC%89"><span class="nav-text">Problem (unicode2): unicode编码（3分）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-%E5%AD%90%E8%AF%8D%E5%88%86%E8%AF%8D%E6%96%B9%E6%A1%88%EF%BC%88subword-tokenization%EF%BC%89"><span class="nav-text">2.3 子词分词方案（subword tokenization）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-4-%E8%AE%AD%E7%BB%83BPE%E5%88%86%E8%AF%8D%E5%99%A8"><span class="nav-text">2.4 训练BPE分词器</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E5%88%9D%E5%A7%8B%E5%8C%96-vocabulary"><span class="nav-text">1 初始化 vocabulary</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E9%A2%84%E5%88%86%E8%AF%8D%EF%BC%88Pre-tokenization"><span class="nav-text">2 预分词（Pre-tokenization)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E8%AE%A1%E7%AE%97BPE%E5%90%88%E5%B9%B6-amp-%E5%A4%84%E7%90%86%E7%89%B9%E6%AE%8Atoken"><span class="nav-text">3 计算BPE合并&amp;处理特殊token</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E4%B8%AA%E8%AE%AD%E7%BB%83%E7%9A%84%E5%85%B7%E4%BD%93%E4%BE%8B%E5%AD%90%EF%BC%9A"><span class="nav-text">一个训练的具体例子：</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E5%88%9D%E5%A7%8B%E5%8C%96vocabulary%EF%BC%9A"><span class="nav-text">1 初始化vocabulary：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-Pre-tokenization"><span class="nav-text">2 Pre-tokenization:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E5%90%88%E5%B9%B6%EF%BC%9A"><span class="nav-text">3 合并：</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-5-%E5%AE%9E%E9%AA%8C%EF%BC%9A%E8%AE%AD%E7%BB%83BPE"><span class="nav-text">2.5 实验：训练BPE</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86%E9%A2%84%E5%88%86%E8%AF%8D"><span class="nav-text">1 并行处理预分词</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E9%A2%84%E5%88%86%E8%AF%8D%E5%89%8D%EF%BC%8C%E5%89%94%E9%99%A4%E7%89%B9%E6%AE%8Atoken%E4%B8%8D%E8%BF%9B%E8%A1%8C%E5%A4%84%E7%90%86"><span class="nav-text">2 预分词前，剔除特殊token不进行处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E4%BC%98%E5%8C%96%E5%90%88%E5%B9%B6"><span class="nav-text">3 优化合并</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Downscaling-%E6%8F%90%E7%A4%BA"><span class="nav-text">Downscaling 提示</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Problem-train-bpe-BPE%E8%AE%AD%E7%BB%83%EF%BC%8815%E5%88%86%EF%BC%89"><span class="nav-text">Problem (train_bpe): BPE训练（15分）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Problem-train-bpe-tinystories-%EF%BC%9ATinyStories%E4%B8%8A%E7%9A%84%E8%AE%AD%E7%BB%83%EF%BC%882%E5%88%86%EF%BC%89"><span class="nav-text">Problem (train_bpe_tinystories)：TinyStories上的训练（2分）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Answer%EF%BC%9A"><span class="nav-text">Answer：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Deliverable"><span class="nav-text">Deliverable:</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Problem-train-bpe-expts-owt-OpenWebText%E4%B8%8A%E7%9A%84%E8%AE%AD%E7%BB%83%EF%BC%882%E5%88%86%EF%BC%89"><span class="nav-text">Problem (train_bpe_expts_owt): OpenWebText上的训练（2分）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Answer"><span class="nav-text">Answer:</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-6-BPE%EF%BC%9A%E7%BC%96%E7%A0%81%E5%92%8C%E8%A7%A3%E7%A0%81"><span class="nav-text">2.6 BPE：编码和解码</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-6-1-Encoding-%E6%96%87%E6%9C%AC"><span class="nav-text">2.6.1 Encoding 文本</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-6-2-Decoding-%E6%96%87%E6%9C%AC"><span class="nav-text">2.6.2 Decoding 文本</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Problem-tokenizer-%E5%AE%9E%E7%8E%B0%E5%88%86%E8%AF%8D%E5%99%A8%EF%BC%8815%E5%88%86%EF%BC%89"><span class="nav-text">Problem (tokenizer): 实现分词器（15分）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Answer%EF%BC%9A-1"><span class="nav-text">Answer：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-7-%E5%AE%9E%E9%AA%8C"><span class="nav-text">2.7 实验</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Answer%EF%BC%9A-2"><span class="nav-text">Answer：</span></a></li></ol></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zian Wang"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Zian Wang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">3</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="/" title="Shanghai → &#x2F;" rel="noopener me"><i class="fa fa-map-marker-alt fa-fw"></i>Shanghai</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://zian-2.github.io/" title="Website → https:&#x2F;&#x2F;zian-2.github.io&#x2F;" rel="noopener me" target="_blank"><i class="fa fa-globe fa-fw"></i>Website</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://github.com/zian-2" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zian-2" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:w3382864761@gmail.com" title="E-Mail → mailto:w3382864761@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2026/01/24/Assignment1-basics-chapter1&2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Zian Wang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Homepage">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="cs336：Assignment1-basics-chapter1&amp;2 | Homepage">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          cs336：Assignment1-basics-chapter1&2
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2026-01-24 22:15:15" itemprop="dateCreated datePublished" datetime="2026-01-24T22:15:15+08:00">2026-01-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2026-02-02 20:18:17" itemprop="dateModified" datetime="2026-02-02T20:18:17+08:00">2026-02-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/cs336/" itemprop="url" rel="index"><span itemprop="name">cs336</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>本文为cs336的assignment1中分词器对应章节的参考解答和课程笔记。   </p>
<p>1 本文范围内的作业暂时还不需要用到GPU<br>2 本课程并未提供好系统适配，所以事实上不推荐在win上完成作业。在你的服务器or虚拟机上完成可以避免很多麻烦。</p>
<h1 id="Setup："><a href="#Setup：" class="headerlink" title="Setup："></a>Setup：</h1><h2 id="环境配置："><a href="#环境配置：" class="headerlink" title="环境配置："></a>环境配置：</h2><p>按照<a target="_blank" rel="noopener" href="https://github.com/stanford-cs336/assignment1-basics/tree/main">https://github.com/stanford-cs336/assignment1-basics/tree/main</a> 中README的说明配置并测试uv。  </p>
<p>如果你在Windows下，uv run pytest 时会出现问题，因为你没有办法import resource。<br>进行如下操作：<br>打开\assignment1-basics\tests\test_tokenizer.py， 删除第5行的import resource，或修改：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">import</span> resource</span><br><span class="line"><span class="keyword">except</span> ImportError:</span><br><span class="line">    resource = <span class="literal">None</span></span><br></pre></td></tr></table></figure>
<p>然后重新uv run pytest。  </p>
<h2 id="数据下载："><a href="#数据下载：" class="headerlink" title="数据下载："></a>数据下载：</h2><p>下载 TinyStories data 和 subsample of OpenWebText：<br>课程原生使用的是wget； windows下，推荐使用curl。试着使用如下命令：<br><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建并进入数据目录</span></span><br><span class="line">mkdir <span class="literal">-p</span> <span class="keyword">data</span></span><br><span class="line"><span class="built_in">cd</span> <span class="keyword">data</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载 TinyStories</span></span><br><span class="line">curl.exe <span class="literal">-L</span> <span class="literal">-o</span> TinyStoriesV2<span class="literal">-GPT4-train</span>.txt https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2<span class="literal">-GPT4-train</span>.txt</span><br><span class="line">curl.exe <span class="literal">-L</span> <span class="literal">-o</span> TinyStoriesV2<span class="literal">-GPT4-valid</span>.txt https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2<span class="literal">-GPT4-valid</span>.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载 OpenWebText</span></span><br><span class="line">curl.exe <span class="literal">-L</span> <span class="literal">-o</span> owt_train.txt.gz https://huggingface.co/datasets/stanford<span class="literal">-cs336</span>/owt<span class="literal">-sample</span>/resolve/main/owt_train.txt.gz</span><br><span class="line">curl.exe <span class="literal">-L</span> <span class="literal">-o</span> owt_valid.txt.gz https://huggingface.co/datasets/stanford<span class="literal">-cs336</span>/owt<span class="literal">-sample</span>/resolve/main/owt_valid.txt.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压 .gz 文件</span></span><br><span class="line"><span class="comment"># Windows 10/11 自带 tar.exe，可以替代 gunzip</span></span><br><span class="line">tar.exe <span class="literal">-xvzf</span> owt_train.txt.gz</span><br><span class="line">tar.exe <span class="literal">-xvzf</span> owt_valid.txt.gz</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> ..</span><br></pre></td></tr></table></figure></p>
<p>如果解压不成功，考虑使用python原生解压。<br><span id="more"></span></p>
<p>先输入python进入交互模式，然后：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> gzip.<span class="built_in">open</span>(<span class="string">&#x27;owt_valid.txt.gz&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f_in:</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;owt_valid.txt&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f_out:</span><br><span class="line">        shutil.copyfileobj(f_in, f_out)</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<p><br> <br><br> </p>
<h1 id="1-作业总览"><a href="#1-作业总览" class="headerlink" title="1 作业总览"></a>1 作业总览</h1><p>你将构建训练标准 Transformer LM 所需的所有组件，并训练一些模型。</p>
<h3 id="你将实现："><a href="#你将实现：" class="headerlink" title="你将实现："></a>你将实现：</h3><p>1 BPE 分词器 (Byte-pair encoding tokenizer)：第 2 节<br>2 Transformer 语言模型 (LM)：第 3 节<br>3 交叉熵损失函数与 AdamW 优化器：第 4 节<br>4 训练循环：支持模型和优化器状态的序列化与加载（保存与读取）：第 5 节  </p>
<h3 id="你将完成如下任务："><a href="#你将完成如下任务：" class="headerlink" title="你将完成如下任务："></a>你将完成如下任务：</h3><p>1 在 TinyStories 数据集上训练一个 BPE 分词器。<br>2 对数据集运行训练好的分词器，将其转换为整数 ID 序列。<br>3 在 TinyStories 数据集上训练 Transformer 语言模型。<br>4 使用训练好的模型生成样本并评估困惑度 (Perplexity)。<br>5 在 OpenWebText 数据集上训练模型，并将达到的困惑度结果提交到排行榜。  </p>
<h3 id="允许使用的工具："><a href="#允许使用的工具：" class="headerlink" title="允许使用的工具："></a>允许使用的工具：</h3><p>课程希望你从0开始搭组件，所以不得使用<code>torch.nn</code>、<code>torch.nn.functional</code> 或 <code>torch.optim</code> 中的任何定义，除了：</p>
<p>1 <code>torch.nn.Parameter</code><br>2 <code>torch.nn</code> 中的容器类（<code>Module</code>, <code>ModuleList</code>, <code>Sequential</code> 等）<br>3 <code>torch.optim.Optimizer</code> 基类   </p>
<h3 id="关于-AI-工具："><a href="#关于-AI-工具：" class="headerlink" title="关于 AI 工具："></a>关于 AI 工具：</h3><p>1 允许使用大语言模型进行低级的编程问题或提问高级的概念问题的咨询，但严禁直接使用 AI 来完成作业题目。<br>2 建议在完成作业时关闭 IDE 中的 AI 自动补全（如 Cursor Tab, GitHub CoPilot）。</p>
<h3 id="数据集获取："><a href="#数据集获取：" class="headerlink" title="数据集获取："></a>数据集获取：</h3><p>本次作业使用两个预处理过的数据集：TinyStories 和 OpenWebText。两者都是大型纯文本文件。<br>校内学生可在实验室机器的 <code>/data</code> 目录下找到。校外人员/自学者可根据<strong>README.md中的命令下载。</strong></p>
<h3 id="降低规模的建议："><a href="#降低规模的建议：" class="headerlink" title="降低规模的建议："></a>降低规模的建议：</h3><p>后续课程会提供建议，解释如何在 CPU 或 MPS 环境下进行调整。</p>
<p><br> <br> <br></p>
<h1 id="2-BPE-Byte-Pair-Encoding-分词器"><a href="#2-BPE-Byte-Pair-Encoding-分词器" class="headerlink" title="2 BPE(Byte-Pair Encoding)分词器"></a>2 BPE(Byte-Pair Encoding)分词器</h1><h2 id="2-1-unicode标准"><a href="#2-1-unicode标准" class="headerlink" title="2.1 unicode标准"></a>2.1 unicode标准</h2><p>Unicode标准将字符映射到整数code points上。例如”s” 的code point 是115（或写作十六进制的U+0073），”牛”对应29275。</p>
<p>python中，有ord()和chr()函数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="built_in">ord</span>(<span class="string">&#x27;牛&#x27;</span>)</span><br><span class="line"><span class="number">29275</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">chr</span>(<span class="number">29275</span>)</span><br><span class="line"><span class="string">&#x27;牛&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h3 id="Problem-unicode1-unicode介绍-（1分）"><a href="#Problem-unicode1-unicode介绍-（1分）" class="headerlink" title="Problem (unicode1): unicode介绍 （1分）"></a>Problem (unicode1): unicode介绍 （1分）</h3><p>(a)<code>chr(0)</code> 返回的是什么字符？<br><code>chr(0)</code> 返回的是 Unicode 编码为 0 的字符，即空字符（Null Character）。</p>
<p>(b) 它的字符串表示形式 (<code>__repr__()</code>) 与打印形式有何不同？<br>在 Python 中，其字符串表示形式（<code>__repr__()</code>）会显示为转义序列 <code>&#39;\x00&#39;</code>，而打印该字符（<code>print()</code>）时通常是不可见的，在某些终端里可能显示为空格。</p>
<p>(c)当该字符出现在文本中时会发生什么？<br>在 Python 字符串内部它可以正常存在并拼接，但在将其打印到终端或与底层 C 语言编写的程序交互时，它可能会被当做文本结束符而导致后面的内容被截断，或者干脆显示为一个空白区域。</p>
<p><br> <br></p>
<h2 id="2-2-unicode编码"><a href="#2-2-unicode编码" class="headerlink" title="2.2 unicode编码"></a>2.2 unicode编码</h2><p>主要介绍了UTF-8。编码和解码UTF-8的函数包括encode()和decode()，如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>test_string = <span class="string">&quot;hello! こんにちは!&quot;</span> </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>utf8_encoded = test_string.encode(<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(utf8_encoded) </span><br><span class="line"><span class="string">b&#x27;hello! \xe3\x81\x93\xe3\x82\x93\xe3\x81\xab\xe3\x81\xa1\xe3\x81\xaf!&#x27;</span> </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">type</span>(utf8_encoded))</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;bytes&#x27;</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Get the byte values for the encoded string (integers from 0 to 255).</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(utf8_encoded) </span><br><span class="line">[<span class="number">104</span>, <span class="number">101</span>, <span class="number">108</span>, <span class="number">108</span>, <span class="number">111</span>, <span class="number">33</span>, <span class="number">32</span>, <span class="number">227</span>, <span class="number">129</span>, <span class="number">147</span>, <span class="number">227</span>, <span class="number">130</span>, <span class="number">147</span>, <span class="number">227</span>, <span class="number">129</span>, <span class="number">171</span>, <span class="number">227</span>, <span class="number">129</span>, <span class="number">161</span>, <span class="number">227</span>, <span class="number">129</span>, <span class="number">175</span>, <span class="number">33</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># One byte does not necessarily correspond to one Unicode character! </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">len</span>(test_string)) </span><br><span class="line"><span class="number">13</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">len</span>(utf8_encoded))</span><br><span class="line"><span class="number">23</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(utf8_encoded.decode(<span class="string">&quot;utf-8&quot;</span>)) <span class="number">1</span></span><br><span class="line">hello! こんにちは!</span><br></pre></td></tr></table></figure></p>
<p>我们将整数的codepoints转换成了一个byte序列，它们会更易于处理。例如，因为任何文本实质上都被转化为介于 $0-255$ 之间的整数序列，只要词表包含了这 256 个基础字节，就不需要担心训练和搭建的过程中词表外（OOV）词汇。</p>
<h3 id="课程文档外的补充：UTF-8字节序列对应规则"><a href="#课程文档外的补充：UTF-8字节序列对应规则" class="headerlink" title="课程文档外的补充：UTF-8字节序列对应规则"></a>课程文档外的补充：UTF-8字节序列对应规则</h3><p>字节数1：<br>对应Unicode编码范围：U+0000 至 U+007F 或 0~127 (7 bits)<br>对应utf-8字节序列：0xxxxxxx</p>
<p>字节数2：<br>对应Unicode编码范围：U+0080 至 U+07FF 或 128~2047 (11 bits)<br>对应utf-8字节序列：110xxxxx 10xxxxxx</p>
<p>字节数3：<br>对应Unicode编码范围：U+0800 至 U+FFFF 或 2048~65535 (16 bits)<br>对应utf-8字节序列：1110xxxx 10xxxxxx 10xxxxxx</p>
<p>字节数4：<br>对应Unicode编码范围：U+10000 至 U+10FFFF 或 65536~1114111 (21 bits)<br>应utf-8字节序列：11110xxx 10xxxxxx 10xxxxxx 10xxxxxx</p>
<p>对应方式：先把unicode编码翻译成二进制，在填入对应字节序列的’x’处。（长度不够填则在左侧补0）。</p>
<h3 id="Problem-unicode2-unicode编码（3分）"><a href="#Problem-unicode2-unicode编码（3分）" class="headerlink" title="Problem (unicode2): unicode编码（3分）"></a>Problem (unicode2): unicode编码（3分）</h3><p>(a) 为什么 Tokenizer 训练更偏好 UTF-8而不是UTF-16, UTF-32？<br>UTF-8 是变长编码，能够将常用的 ASCII 字符保持为单字节，避免了 UTF-16/32 在处理英文或代码时产生大量冗余零字节。</p>
<p>(b) 错误的解码函数分析：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">decode_utf8_bytes_to_str_wrong</span>(<span class="params">bytestring: <span class="built_in">bytes</span></span>): </span><br><span class="line">	<span class="keyword">return</span> <span class="string">&quot;&quot;</span>.join([<span class="built_in">bytes</span>([b]).decode(<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">for</span> b <span class="keyword">in</span> bytestring]) </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>decode_utf8_bytes_to_str_wrong(<span class="string">&quot;hello&quot;</span>.encode(<span class="string">&quot;utf-8&quot;</span>)) <span class="string">&#x27;hello&#x27;</span></span><br></pre></td></tr></table></figure></p>
<p>错误输入：如<code>b&#39;\xe4\xb8\xad&#39;</code> （汉字“中”的编码字节流）<br>因为UTF-8 中的中文字符或复杂符号是由 2 到 4 个字节共同组成的，单独解码其中任何一个字节都会因不符合 UTF-8 规范而报错（或产生乱码）。</p>
<p>(c)给出无法解码的字节：<br>如<code>b&#39;\xff\xff&#39;</code>。<br>原因：任何以 <code>11111xxx</code> 开头的字节都没有对应的 5 字节或更长的有效模板，无法解码为任何 Unicode 字符。</p>
<p><br> <br></p>
<h2 id="2-3-子词分词方案（subword-tokenization）"><a href="#2-3-子词分词方案（subword-tokenization）" class="headerlink" title="2.3 子词分词方案（subword tokenization）"></a>2.3 子词分词方案（subword tokenization）</h2><p>将词语拆成byte序列之后，仍然不能逐个byte拆分来看作为token：这会导致序列变得极长，训练的step变长，计算量也增大（如transformer计算复杂度与序列长度成正比）；同时更长的序列也导致信息密度被稀释，网络寻找token间的关系变得更困难。</p>
<p>而subword tokenization就是指代这样一个折中的方案。它选择用一个更大的词汇表(vocabulary)来trade-off更短的序列。比如说，如果‘the’经常出现，我们就可以给它单独分配一个条目(entry)，词汇表维度+1，但把3个token缩短成了1个。</p>
<p>为了做这样的工作，Sennrich et al. (2016) 提出使用byte-pair encoding (BPE; Gage, 1994)。作为一种subword tokenization，它简单地基于出现频率，将经常出现的byte pair合并(merge)成一个未被使用的索引。基于BPE的subword tokenizer被称为BPE tokenizer。</p>
<p><br> <br></p>
<h2 id="2-4-训练BPE分词器"><a href="#2-4-训练BPE分词器" class="headerlink" title="2.4 训练BPE分词器"></a>2.4 训练BPE分词器</h2><h3 id="1-初始化-vocabulary"><a href="#1-初始化-vocabulary" class="headerlink" title="1 初始化 vocabulary"></a>1 初始化 vocabulary</h3><p>初始化的vocabulary是从byte到整数ID的映射。因此，vocabulary的大小为256。</p>
<h3 id="2-预分词（Pre-tokenization"><a href="#2-预分词（Pre-tokenization" class="headerlink" title="2 预分词（Pre-tokenization)"></a>2 预分词（Pre-tokenization)</h3><p>理论上，有了词汇表我们就可以开始进行上述的合并（merge）工作了。然而，有两个关键的问题：<br>i 每次合并的时候，都需要从头到尾过一遍语料库。这在计算上是很昂贵的。<br>ii 直接合并会导致出现一些新的token，它们只有标点符号的区别（比如”dog.“和”dog!“），它们会拥有完全不同的ID，即使它们在语义上是完全相同的。  </p>
<p>为了解决上述问题，我们进行对语料库的预分词(pre-tokenize)，先把语料库切成单词。这是如何省下计算成本的？举个例子，当我们已经计数了’text’的出现次数（比如说10次），当我们需要计数’te’的出现次数时，就可以直接+=10，从而避免了每次遇到同一个单词时重复的计算。</p>
<p>早期分词方案包括直接通过空格进行切分（s.split(“”))，但显然这不能解决上述提到的问题2。</p>
<p>于是，我们将使用的时一个基于正则表达式(regex)的分词器 (used by GPT-2; Radford et al., 2019)，可以在github.com/openai/tiktoken/pull/234/files中找到。如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>PAT = <span class="string">r&quot;&quot;&quot;&#x27;(?:[sdmt]|ll|ve|re)| ?\p&#123;L&#125;+| ?\p&#123;N&#125;+| ?[^\s\p&#123;L&#125;\p&#123;N&#125;]+|\s+(?!\S)|\s+&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>这里的五个部分分别处理：缩写后缀（’ll, ‘ve, ‘t , ‘s等）；连续字母（单词）；连续数字；连续标点符号；连续纯空格。</p>
<p>例子如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># requires `regex` package </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> regex <span class="keyword">as</span> re </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span> re.findall(PAT, <span class="string">&quot;some text that i&#x27;ll pre-tokenize&quot;</span>) </span><br><span class="line">[<span class="string">&#x27;some&#x27;</span>, <span class="string">&#x27; text&#x27;</span>, <span class="string">&#x27; that&#x27;</span>, <span class="string">&#x27; i&#x27;</span>, <span class="string">&quot;&#x27;ll&quot;</span>, <span class="string">&#x27; pre&#x27;</span>, <span class="string">&#x27;-&#x27;</span>, <span class="string">&#x27;tokenize&#x27;</span>]</span><br></pre></td></tr></table></figure></p>
<p>实际使用中，用findall内存容易溢出，建议使用re.finditer这一迭代计算的函数。</p>
<h3 id="3-计算BPE合并-amp-处理特殊token"><a href="#3-计算BPE合并-amp-处理特殊token" class="headerlink" title="3 计算BPE合并&amp;处理特殊token"></a>3 计算BPE合并&amp;处理特殊token</h3><p>现在我们可以开始按照前述方法计算合并了。只需要注意两点：<br>i  不能跨越预分词边界合并。<code>[&#39;some&#39;, &#39;text&#39;]</code>，那么 <code>e</code>（来自 some）和 <code>t</code>（来自 text）永远不会被统计在一起。<br>ii 多个byte pair出现频率并列第一时，选择字典序最大（Lexicographically greater）的那一对。(“A”, “B”), (“A”, “C”), (“B”, “ZZ”), 和 (“BA”, “A”)频率相同时，在 ASCII 中 “BA” &gt; “B” &gt; “A”），因此 <code>max</code> 会选出 <code>(&#39;BA&#39;, &#39;A&#39;)</code>。<br>iii 有一些特殊token不能和其他合并，比如&lt;|endoftext|&gt;。它不应该被分成几个零碎的token，因此我们会给它安排一个固定的tokenID。  </p>
<h3 id="一个训练的具体例子："><a href="#一个训练的具体例子：" class="headerlink" title="一个训练的具体例子："></a>一个训练的具体例子：</h3><p>例如我们现在有如下corpus：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">low low low low </span><br><span class="line">low lower lower widest widest widest </span><br><span class="line">newest newest newest newest newest newest</span><br></pre></td></tr></table></figure><br>, 且vocabulary里已经放好了&lt;|endoftext|&gt;这一special token。</p>
<h4 id="1-初始化vocabulary："><a href="#1-初始化vocabulary：" class="headerlink" title="1 初始化vocabulary："></a>1 初始化vocabulary：</h4><p>一个special token和256个byte value。</p>
<h4 id="2-Pre-tokenization"><a href="#2-Pre-tokenization" class="headerlink" title="2 Pre-tokenization:"></a>2 Pre-tokenization:</h4><p>为了简化，我们仅使用用空格分隔，最终得到频率表：{low: 5, lower: 2, widest: 3, newest: 6}。为容易处理，将它写成dict[tuple[bytes], int]的格式，如{(l,o,w): 5 …}。</p>
<h4 id="3-合并："><a href="#3-合并：" class="headerlink" title="3 合并："></a>3 合并：</h4><p>数出上述例子中byte pair的出现频率：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;lo: <span class="number">7</span>, ow: <span class="number">7</span>, we: <span class="number">8</span>, er: <span class="number">2</span>, wi: <span class="number">3</span>, <span class="built_in">id</span>: <span class="number">3</span>, de: <span class="number">3</span>, es: <span class="number">9</span>, st: <span class="number">9</span>, ne: <span class="number">6</span>, ew: <span class="number">6</span>&#125;</span><br></pre></td></tr></table></figure><br>(‘es’) 和 (‘st’)并列，我们就取字典序更大的(‘st’)。<br>于是表格变为：{(l,o,w): 5, (l,o,w,e,r): 2, (w,i,d,e,st): 3, (n,e,w,e,st): 6}.</p>
<p>如是循环，进行6次merge，可以得到新产生的vocabulary：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">&#x27;s t&#x27;</span>, <span class="string">&#x27;e st&#x27;</span>, <span class="string">&#x27;o w&#x27;</span>, <span class="string">&#x27;l ow&#x27;</span>, <span class="string">&#x27;w est&#x27;</span>, <span class="string">&#x27;n e&#x27;</span>]</span><br></pre></td></tr></table></figure></p>
<p>于是新的词汇表变为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&lt;|endoftext|&gt;, [..<span class="number">.256</span> BYTE CHARS], st, est, ow, low, west, ne]</span><br></pre></td></tr></table></figure></p>
<p>在此语境下，‘newest’ 将被分词为[ne, west]。</p>
<p><br> <br></p>
<h2 id="2-5-实验：训练BPE"><a href="#2-5-实验：训练BPE" class="headerlink" title="2.5 实验：训练BPE"></a>2.5 实验：训练BPE</h2><p>我们接下来再TinyStories数据集上训练一个BPE。你可以在Section1里找到它的下载方式。在开始之前，推荐你先大概看一眼里面都是什么内容。</p>
<h3 id="1-并行处理预分词"><a href="#1-并行处理预分词" class="headerlink" title="1 并行处理预分词"></a>1 并行处理预分词</h3><p>训练过程中，预分词会是一个主要的瓶颈。你可以使用内置库<code>multiprocessing</code>并行化你的代码。<br>你可以逐字使用以下链接中的入门代码来获取分块边界，然后使用这些边界将工作分配到各个进程：<br><a target="_blank" rel="noopener" href="https://github.com/stanford-cs336/assignment1-basics/blob/main/cs336_basics/pretokenization_example.py">https://github.com/stanford-cs336/assignment1-basics/blob/main/cs336_basics/pretokenization_example.py</a><br>阅读此代码，你会发现它实现的是确保每个分块边界都切割在special_token之前。</p>
<h3 id="2-预分词前，剔除特殊token不进行处理"><a href="#2-预分词前，剔除特殊token不进行处理" class="headerlink" title="2 预分词前，剔除特殊token不进行处理"></a>2 预分词前，剔除特殊token不进行处理</h3><p>用”|” .join(special_tokens)来re.split以移除&lt;|endoftext|&gt;</p>
<h3 id="3-优化合并"><a href="#3-优化合并" class="headerlink" title="3 优化合并"></a>3 优化合并</h3><p>naive BPE training（逐个合并，每次合并从头遍历一次）计算量太大。考虑到每次合并改变的计数只有这个合并前后的计数，我们可以动态处理合并，即每次合并只将前后的计数-1。如合并‘text’中的‘ex’，只需要将te和xt的计数-1，而不需要合并完之后再从头数一遍。</p>
<h3 id="Downscaling-提示"><a href="#Downscaling-提示" class="headerlink" title="Downscaling 提示"></a>Downscaling 提示</h3><p>1 cProfile和scalene等分析工具可以分析你的实现中的瓶颈，于是你可以专注于分析这些瓶颈。<br>2 与其直接现在TInyStories的training set上训练，你可以先将validation set作为‘调试数据(debug dataset)’训练。后者只有22K个文档，前者有2.12M个文档。</p>
<h3 id="Problem-train-bpe-BPE训练（15分）"><a href="#Problem-train-bpe-BPE训练（15分）" class="headerlink" title="Problem (train_bpe): BPE训练（15分）"></a>Problem (train_bpe): BPE训练（15分）</h3><p>1 编写你的tokenizer，然后在adapter.py中import，最后uv run pytest tests/test_train_bpe.py。<br>需要注意，如果出现类似” Extra items in the left set: b’\r\n\r’  “的报错，这是因为linux文本会被windows自动将\n更改为\r\n。这也很好解决，直接处理一步.replace(b”\r\n”, b”\n”)即可。    </p>
<p>笔者的个人实现见<br><a target="_blank" rel="noopener" href="https://github.com/Zian-2/cs336_assignments_and_notes/blob/main/assignment1-basics/cs336_basics/tokenizer.py">https://github.com/Zian-2/cs336_assignments_and_notes/blob/main/assignment1-basics/cs336_basics/tokenizer.py</a>  ，<br>本节答案对应截止在#—2.6 Encoding &amp; Decoding—#上方的内容。<br>对其的说明参考<a target="_blank" rel="noopener" href="https://zian-2.github.io/2026/01/21/tokenizer.py/">https://zian-2.github.io/2026/01/21/tokenizer.py/</a>  </p>
<p>2 按照文章的建议，You should use profiling tools like <strong><code>cProfile</code></strong> or <strong><code>scalene</code></strong> to identify the bottlenecks in your implementation.  个人的实现，在主函数内部添加如下代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_bpe</span>(<span class="params">input_path, vocab_size, special_tokens, num_chunks = <span class="number">1000</span></span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> cProfile, pstats</span><br><span class="line">    profiler = cProfile.Profile()</span><br><span class="line">    profiler.enable() <span class="comment"># 开始分析</span></span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"><span class="comment">##############################################</span></span><br><span class="line"><span class="comment">#  你的完整的分词进程</span></span><br><span class="line"><span class="comment">##############################################</span></span><br><span class="line"></span><br><span class="line">    profiler.disable() <span class="comment"># 结束分析</span></span><br><span class="line">    stats = pstats.Stats(profiler).sort_stats(<span class="string">&#x27;cumulative&#x27;</span>)</span><br><span class="line">    stats.print_stats(<span class="number">15</span>) <span class="comment"># 打印耗时最长的 15 个函数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tokenizer</span><br></pre></td></tr></table></figure></p>
<p>添加分析之后运行时长增加是正常的。注意在表格中只需要关注tottime（函数内部的运行时长，不包括调用的外部函数）。</p>
<h3 id="Problem-train-bpe-tinystories-：TinyStories上的训练（2分）"><a href="#Problem-train-bpe-tinystories-：TinyStories上的训练（2分）" class="headerlink" title="Problem (train_bpe_tinystories)：TinyStories上的训练（2分）"></a>Problem (train_bpe_tinystories)：TinyStories上的训练（2分）</h3><p>(a) 在 TinyStories 数据集上训练一个字节级（byte-level）的 BPE 分词器，词表最大容量为 10,000。确保在词表中加入 <code>&lt;|endoftext|&gt;</code> 特殊标记。将生成的词表（vocabulary）和合并规则（merges）序列化保存到磁盘以便后续检查。训练耗时多少小时？消耗了多少内存？词表中最长的 Token 是什么？它合理吗？</p>
<p>资源要求： 耗时 ≤ 30 分钟（不使用 GPU），内存 ≤ 30GB RAM。<br>提示：你可以使用multiprocessing，可以使训练达到2分钟以内（这里应该指的是训练集TinyStoriesV2-GPT4-train.txt）</p>
<p>(b) 对你的代码进行性能分析（Profile）。分词器训练过程中哪个部分最耗时？</p>
<h4 id="Answer："><a href="#Answer：" class="headerlink" title="Answer："></a>Answer：</h4><p>你需要先把TinyStories接上你的分词器。记录内存消耗峰值，同时用cProfile分析，最后输出longest token，并将vocab和merges导入到你的磁盘里。参考实现如下（不包括profile）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> .tokenizer <span class="keyword">import</span> train_bpe</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="comment"># 路径配置</span></span><br><span class="line">    input_path = <span class="string">&quot;../data/TinyStoriesV2-GPT4-valid.txt&quot;</span></span><br><span class="line">    vocab_size = <span class="number">10000</span> </span><br><span class="line">    special_tokens = [<span class="string">&quot;&lt;|endoftext|&gt;&quot;</span>] </span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;开始训练&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 调用训练函数</span></span><br><span class="line">    tokenizer = train_bpe(</span><br><span class="line">        input_path=input_path,</span><br><span class="line">        vocab_size=vocab_size,</span><br><span class="line">        special_tokens=special_tokens,</span><br><span class="line">        num_chunks=<span class="number">1000</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n训练完成&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;词表大小: <span class="subst">&#123;<span class="built_in">len</span>(tokenizer.vocab)&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;合并次数: <span class="subst">&#123;<span class="built_in">len</span>(tokenizer.merges)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    output_dir = <span class="string">&quot;run_bpe_train_on_tinystories_output&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(output_dir):</span><br><span class="line">        os.makedirs(output_dir)</span><br><span class="line"></span><br><span class="line">    readable_vocab = &#123;<span class="built_in">int</span>(k): <span class="built_in">list</span>(v) <span class="keyword">for</span> k, v <span class="keyword">in</span> tokenizer.vocab.items()&#125;</span><br><span class="line">    vocab_path = os.path.join(output_dir, <span class="string">&quot;vocab.json&quot;</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(vocab_path, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        json.dump(readable_vocab, f, indent=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    merges_path = os.path.join(output_dir, <span class="string">&quot;merges.txt&quot;</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(merges_path, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> p1, p2 <span class="keyword">in</span> tokenizer.merges:</span><br><span class="line">            <span class="comment"># 将 bytes 转换为逗号分隔的数字字符串</span></span><br><span class="line">            s1 = <span class="string">&quot;,&quot;</span>.join(<span class="built_in">map</span>(<span class="built_in">str</span>, <span class="built_in">list</span>(p1)))</span><br><span class="line">            s2 = <span class="string">&quot;,&quot;</span>.join(<span class="built_in">map</span>(<span class="built_in">str</span>, <span class="built_in">list</span>(p2)))</span><br><span class="line">            f.write(<span class="string">f&quot;<span class="subst">&#123;s1&#125;</span> <span class="subst">&#123;s2&#125;</span>\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></p>
<h4 id="Deliverable"><a href="#Deliverable" class="headerlink" title="Deliverable:"></a>Deliverable:</h4><p>(a)  笔者的实现参考：<a target="_blank" rel="noopener" href="https://github.com/Zian-2/cs336_assignments_and_notes/blob/main/assignment1-basics/cs336_basics/tokenizer.py">https://github.com/Zian-2/cs336_assignments_and_notes/blob/main/assignment1-basics/cs336_basics/tokenizer.py</a> 。<br>在TinyStoriesV2-GPT4-train.txt上训练在40秒以内，内存峰值0.8938 GB。<br>设备条件：28GB内存，Intel Core Ultra 7 255HX CPU。<br>longest token: ‘ accomplishment’。输出合理。</p>
<p>(b)Profile : 你可以以任何方式完成Profile。在TinyStoriesV2-GPT4-train.txt上的参考profile如下：<br><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">==================================================</span><br><span class="line">Profile (Top <span class="number">20</span> Functions):</span><br><span class="line">         <span class="number">15808949</span> <span class="function"><span class="keyword">function</span> <span class="title">calls</span> <span class="params">(15808073 primitive calls)</span> <span class="title">in</span> <span class="title">40</span>.<span class="title">449</span> <span class="title">seconds</span></span></span><br><span class="line"></span><br><span class="line">   Ordered by: internal time</span><br><span class="line">   List reduced from <span class="number">457</span> to <span class="number">20</span> due to restriction &lt;<span class="number">20</span>&gt;</span><br><span class="line"></span><br><span class="line">   ncalls  tottime  percall  cumtime  percall filename:lineno(function)</span><br><span class="line">  <span class="number">463</span>/<span class="number">235</span>   <span class="number">20.998</span>    <span class="number">0.045</span>    <span class="number">6.500</span>    <span class="number">0.028</span> &#123;built<span class="operator">-in</span> method _winapi.WaitForMultipleObjects&#125;</span><br><span class="line">     <span class="number">9743</span>    <span class="number">7.911</span>    <span class="number">0.001</span>   <span class="number">14.576</span>    <span class="number">0.001</span> D:\cs336_assignments_and_notes\assignment1<span class="literal">-basics</span>\cs336_basics\tokenizer.py:<span class="number">169</span>(merge_step)</span><br><span class="line">    <span class="number">23282</span>    <span class="number">2.899</span>    <span class="number">0.000</span>    <span class="number">2.951</span>    <span class="number">0.000</span> &#123;built<span class="operator">-in</span> method builtins.max&#125;</span><br><span class="line">   <span class="number">277780</span>    <span class="number">2.271</span>    <span class="number">0.000</span>    <span class="number">3.413</span>    <span class="number">0.000</span> D:\cs336_assignments_and_notes\assignment1<span class="literal">-basics</span>\cs336_basics\tokenizer.py:<span class="number">115</span>(_replace_pair_and_pair_counts)</span><br><span class="line">       <span class="number">80</span>    <span class="number">1.486</span>    <span class="number">0.019</span>    <span class="number">1.486</span>    <span class="number">0.019</span> &#123;built<span class="operator">-in</span> method _pickle.loads&#125;</span><br><span class="line">     <span class="number">1002</span>    <span class="number">1.238</span>    <span class="number">0.001</span>    <span class="number">2.147</span>    <span class="number">0.002</span> D:\Program Files\Python313\Lib\collections\__init__.py:<span class="number">673</span>(update)</span><br><span class="line">  <span class="number">6434620</span>    <span class="number">1.028</span>    <span class="number">0.000</span>    <span class="number">1.028</span>    <span class="number">0.000</span> &#123;method <span class="string">&#x27;get&#x27;</span> of <span class="string">&#x27;dict&#x27;</span> objects&#125;</span><br><span class="line">  <span class="number">2538958</span>    <span class="number">0.486</span>    <span class="number">0.000</span>    <span class="number">0.486</span>    <span class="number">0.000</span> &#123;method <span class="string">&#x27;add&#x27;</span> of <span class="string">&#x27;set&#x27;</span> objects&#125;</span><br><span class="line">  <span class="number">1362761</span>    <span class="number">0.374</span>    <span class="number">0.000</span>    <span class="number">0.374</span>    <span class="number">0.000</span> &#123;method <span class="string">&#x27;discard&#x27;</span> of <span class="string">&#x27;set&#x27;</span> objects&#125;</span><br><span class="line">  <span class="number">689</span>/<span class="number">189</span>    <span class="number">0.323</span>    <span class="number">0.000</span>   <span class="number">38.936</span>    <span class="number">0.206</span> &#123;built<span class="operator">-in</span> method _winapi.ReadFile&#125;</span><br><span class="line">        <span class="number">1</span>    <span class="number">0.217</span>    <span class="number">0.217</span>   <span class="number">40.447</span>   <span class="number">40.447</span> D:\cs336_assignments_and_notes\assignment1<span class="literal">-basics</span>\cs336_basics\tokenizer.py:<span class="number">218</span>(train)</span><br><span class="line">  <span class="number">3008052</span>    <span class="number">0.190</span>    <span class="number">0.000</span>    <span class="number">0.190</span>    <span class="number">0.000</span> &#123;built<span class="operator">-in</span> method builtins.len&#125;</span><br><span class="line">   <span class="number">277795</span>    <span class="number">0.156</span>    <span class="number">0.000</span>    <span class="number">0.156</span>    <span class="number">0.000</span> &#123;method <span class="string">&#x27;pop&#x27;</span> of <span class="string">&#x27;dict&#x27;</span> objects&#125;</span><br><span class="line">        <span class="number">1</span>    <span class="number">0.135</span>    <span class="number">0.135</span>    <span class="number">0.196</span>    <span class="number">0.196</span> D:\cs336_assignments_and_notes\assignment1<span class="literal">-basics</span>\cs336_basics\tokenizer.py:<span class="number">149</span>(pair_count)</span><br><span class="line">  <span class="number">1370918</span>    <span class="number">0.133</span>    <span class="number">0.000</span>    <span class="number">0.133</span>    <span class="number">0.000</span> &#123;method <span class="string">&#x27;append&#x27;</span> of <span class="string">&#x27;list&#x27;</span> objects&#125;</span><br><span class="line">       <span class="number">20</span>    <span class="number">0.123</span>    <span class="number">0.006</span>    <span class="number">0.123</span>    <span class="number">0.006</span> &#123;built<span class="operator">-in</span> method _winapi.CreateProcess&#125;</span><br><span class="line">       <span class="number">78</span>    <span class="number">0.092</span>    <span class="number">0.001</span>    <span class="number">0.374</span>    <span class="number">0.005</span> D:\Program Files\Python313\Lib\multiprocessing\connection.py:<span class="number">246</span>(recv)</span><br><span class="line">  <span class="number">794</span>/<span class="number">768</span>    <span class="number">0.051</span>    <span class="number">0.000</span>    <span class="number">0.128</span>    <span class="number">0.000</span> &#123;method <span class="string">&#x27;GetOverlappedResult&#x27;</span> of <span class="string">&#x27;_winapi.Overlapped&#x27;</span> objects&#125;</span><br><span class="line">      <span class="number">157</span>    <span class="number">0.050</span>    <span class="number">0.000</span>    <span class="number">0.050</span>    <span class="number">0.000</span> &#123;method <span class="string">&#x27;write&#x27;</span> of <span class="string">&#x27;_io.BytesIO&#x27;</span> objects&#125;</span><br><span class="line">   <span class="number">270267</span>    <span class="number">0.047</span>    <span class="number">0.000</span>    <span class="number">0.048</span>    <span class="number">0.000</span> D:\cs336_assignments_and_notes\assignment1<span class="literal">-basics</span>\cs336_basics\tokenizer.py:<span class="number">178</span>(&lt;genexpr&gt;)</span><br><span class="line"></span><br><span class="line">==================================================</span><br></pre></td></tr></table></figure></p>
<h3 id="Problem-train-bpe-expts-owt-OpenWebText上的训练（2分）"><a href="#Problem-train-bpe-expts-owt-OpenWebText上的训练（2分）" class="headerlink" title="Problem (train_bpe_expts_owt): OpenWebText上的训练（2分）"></a>Problem (train_bpe_expts_owt): OpenWebText上的训练（2分）</h3><p>(a)在OpenWebText上训练，使用vocab_size = 32000。把你得到的vocab和merges存入硬盘。词表中longest token是什么？合理吗？<br>资源要求： 耗时 ≤ 12小时（不使用 GPU），内存 ≤ 100GB RAM。<br>(b)  对比你分别在TinyStories和OpenWebText上得到的分词器。</p>
<h4 id="Answer"><a href="#Answer" class="headerlink" title="Answer:"></a>Answer:</h4><p>(a) uv run python -m cs336_basics.run_bpe_train_on_openwebtext。<br>longest token基本都是各种长横线或者下划线，你可以通过数据清洗试图避免这一点，但是owt里东西确实比较杂，笔者尝试了一些方法都不能清洗干净。  </p>
<p>(b) id小的词差不多，id大的词区别还是比较明显。owt的词明显更多简写，更不日常，更不口语化；Tiny就有些童话色彩。同样取10000附近的词举例：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">OWT:</span><br><span class="line">&quot;9985&quot;: &quot;82&quot;,</span><br><span class="line">&quot;9986&quot;: &quot; signals&quot;,</span><br><span class="line">&quot;9987&quot;: &quot; oxy&quot;,</span><br><span class="line">&quot;9988&quot;: &quot; eager&quot;,</span><br><span class="line">&quot;9989&quot;: &quot;igg&quot;,</span><br><span class="line">&quot;9990&quot;: &quot;ERS&quot;,</span><br><span class="line">&quot;9991&quot;: &quot; unprecedented&quot;,</span><br><span class="line">&quot;9992&quot;: &quot; mood&quot;,</span><br><span class="line">&quot;9993&quot;: &quot; custody&quot;,</span><br><span class="line">&quot;9994&quot;: &quot; bankrupt&quot;,</span><br><span class="line">&quot;9995&quot;: &quot; asylum&quot;,</span><br><span class="line">&quot;9996&quot;: &quot; acknowledge&quot;,</span><br><span class="line">&quot;9997&quot;: &quot;reek&quot;,</span><br><span class="line">&quot;9998&quot;: &quot;endar&quot;,</span><br><span class="line">&quot;9999&quot;: &quot;books&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">TinyStories:</span><br><span class="line">&quot;9985&quot;: &quot; Froggy&quot;, </span><br><span class="line">&quot;9986&quot;: &quot; wrapper&quot;, </span><br><span class="line">&quot;9987&quot;: &quot; Reddy&quot;, </span><br><span class="line">&quot;9988&quot;: &quot; Hops&quot;, </span><br><span class="line">&quot;9989&quot;: &quot; Crusty&quot;, </span><br><span class="line">&quot;9990&quot;: &quot; whiskers&quot;, </span><br><span class="line">&quot;9991&quot;: &quot; nicest&quot;, </span><br><span class="line">&quot;9992&quot;: &quot; improving&quot;, </span><br><span class="line">&quot;9993&quot;: &quot; booth&quot;, </span><br><span class="line">&quot;9994&quot;: &quot; Land&quot;, </span><br><span class="line">&quot;9995&quot;: &quot; Surrender&quot;, </span><br><span class="line">&quot;9996&quot;: &quot; Rocky&quot;, </span><br><span class="line">&quot;9997&quot;: &quot; meadows&quot;, </span><br><span class="line">&quot;9998&quot;: &quot; imaginary&quot;, </span><br><span class="line">&quot;9999&quot;: &quot; bold&quot;</span><br></pre></td></tr></table></figure></p>
<p>作为对比，再给出32000附近的OWT：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&quot;31985&quot;: &quot; coated&quot;,</span><br><span class="line">&quot;31986&quot;: &quot; bland&quot;,</span><br><span class="line">&quot;31987&quot;: &quot; bending&quot;,</span><br><span class="line">&quot;31988&quot;: &quot; bamboo&quot;,</span><br><span class="line">&quot;31989&quot;: &quot; assurances&quot;,</span><br><span class="line">&quot;31990&quot;: &quot; ambassadors&quot;,</span><br><span class="line">&quot;31991&quot;: &quot; alum&quot;,</span><br><span class="line">&quot;31992&quot;: &quot; Yee&quot;,</span><br><span class="line">&quot;31993&quot;: &quot; Worse&quot;,</span><br><span class="line">&quot;31994&quot;: &quot; Ware&quot;,</span><br><span class="line">&quot;31995&quot;: &quot; Ves&quot;,</span><br><span class="line">&quot;31996&quot;: &quot; TED&quot;,</span><br><span class="line">&quot;31997&quot;: &quot; surveillance&quot;,</span><br><span class="line">&quot;31998&quot;: &quot; Sequ&quot;,</span><br><span class="line">&quot;31999&quot;: &quot; Schaefer&quot;</span><br></pre></td></tr></table></figure><br><br> <br></p>
<h2 id="2-6-BPE：编码和解码"><a href="#2-6-BPE：编码和解码" class="headerlink" title="2.6 BPE：编码和解码"></a>2.6 BPE：编码和解码</h2><p>根据已给的词汇表和merges实现任意文本和vocabulary里的token IDs的互相转换（encode and decode) 。  </p>
<h3 id="2-6-1-Encoding-文本"><a href="#2-6-1-Encoding-文本" class="headerlink" title="2.6.1 Encoding 文本"></a>2.6.1 Encoding 文本</h3><p>步骤：<br>1 预分词 ：这一步和训练的时候是一样的。<br>2 merge：拿出你的vocabulary和merges，按照merges创建时的顺序应用到预分词(pre-token)上。  </p>
<p>一个merge的具体例子：<br>假设输入是 <code>&#39;the cat ate&#39;</code>，<br>词表： <code>&#123;0: b&#39; &#39;, 1: b&#39;a&#39;, 2: b&#39;c&#39;, 3: b&#39;e&#39;, 4: b&#39;h&#39;, 5: b&#39;t&#39;, 6: b&#39;th&#39;, 7: b&#39; c&#39;, 8: b&#39; a&#39;, 9: b&#39;the&#39;, 10: b&#39; at&#39;&#125;</code><br>合并 (merges) 是： <code>[(b&#39;t&#39;, b&#39;h&#39;), (b&#39; &#39;, b&#39;c&#39;), (b&#39; &#39;, b&#39;a&#39;), (b&#39;th&#39;, b&#39;e&#39;), (b&#39; a&#39;, b&#39;t&#39;)]</code></p>
<p>首先预分词，拆成 <code>[&#39;the&#39;, &#39; cat&#39;, &#39; ate&#39;]</code>，然后对每个预分词应用合并。</p>
<p>第一个词 <code>&#39;the&#39;</code> 最初表示为 <code>[b&#39;t&#39;, b&#39;h&#39;, b&#39;e&#39;]</code>。查看合并列表，按顺序逐个应用可用的合并；第一个是 <code>(b&#39;t&#39;, b&#39;h&#39;)</code>，应用它，<code>[b&#39;t&#39;, b&#39;h&#39;, b&#39;e&#39;]</code>转换为 <code>[b&#39;th&#39;, b&#39;e&#39;]</code>。下一个可用的合并是 <code>(b&#39;th&#39;, b&#39;e&#39;)</code>，将 <code>[b&#39;th&#39;, b&#39;e&#39;]</code>转换为 <code>[b&#39;the&#39;]</code>。最后，再次查看合并列表，没有更多可应用的合并则结束。因此得到 ‘the’ 对应的整数序列为 <code>[9]</code>。<br>同样地：<code>&#39; cat&#39;</code> 在应用合并后表示为 <code>[b&#39; c&#39;, b&#39;a&#39;, b&#39;t&#39;]</code>，变为整数序列 <code>[7, 1, 5]</code>。<br> <code>&#39; ate&#39;</code> 合并后为 <code>[b&#39; at&#39;, b&#39;e&#39;]</code>，变为整数序列 <code>[10, 3]</code>。<br>因此，编码输入字符串的最终结果是 <code>[9, 7, 1, 5, 10, 3]</code>。</p>
<p>3 special_tokens： 你的分词器应当能够恰当地对special tokens进行处理。<br>4 内存方面的考量：文件文本常常不能直接塞进内存里，所以还是需要切成chunks再逐个处理，这样无论文件多大，所需的内存才是恒定的，而不是随着文件大小增长所需的内存线性增大。当然，需要保证切开的时候不能把一个token切开。  </p>
<h3 id="2-6-2-Decoding-文本"><a href="#2-6-2-Decoding-文本" class="headerlink" title="2.6.2 Decoding 文本"></a>2.6.2 Decoding 文本</h3><p>Decoding，显然地，就是直接查找ID对应的token然后把它们连接起来，最后再把这些bytes转换成strings。<br>然而，需要注意的是，不是所有输入的ID都能被转换成合法的Unicode strings，所以我们需要把这些畸形的(malformed)bytes替换成官方的unicode替换字符 <code>U+FFFD</code>（参考：<code>https://en.wikipedia.org/wiki/Specials_(Unicode_block)#Replacement_character</code>）。在bytes.decode函数中，参数errors控制了unicode decoding会怎样处理这些错误的bytes。比如说，用<code>errors = &#39;replace&#39;</code>可以自动地把那些畸形的数据替换成替换标记。  </p>
<h3 id="Problem-tokenizer-实现分词器（15分）"><a href="#Problem-tokenizer-实现分词器（15分）" class="headerlink" title="Problem (tokenizer): 实现分词器（15分）"></a>Problem (tokenizer): 实现分词器（15分）</h3><p>要求：实现一个 Tokenizer class，给它输出一个vocabulary和一个merges列表，可以把text文本encode成整数ID或把整数IDdecode成text文本。同时它还应该支持用户提供的特殊token（如果还不在词表里，就把他们添加到词表里。）课程推荐你的把接口写成如下形式：</p>
<p><code>def __init__(self, vocab, merges, special_tokens=None)</code> 从给定的词表、合并列表和（可选的）特殊 Token 列表构造分词器。接受参数包括：<br><code>vocab: dict[int, bytes]</code><br><code>merges: list[tuple[bytes, bytes]]</code><br><code>special_tokens: list[str]  |  None = None</code>  </p>
<p><code>def from_files(cls, vocab_filepath, merges_filepath, special_tokens=None)</code> 一个类方法。从序列化的vocab文件和merges文件（格式与 BPE 训练代码输出的格式相同）构造并返回一个 <code>Tokenizer</code> 实例。参数：<br><code>vocab_filepath: str</code><br><code>merges_ffilepath:  str</code><br><code>special_tokens:  list[str]  |  None = None</code>  </p>
<p><code>def encode(self, text: str) -&gt; list[int]</code>把输入的text文本转换成一列token IDs。  </p>
<p><code>def encode_iterable(self, iterable: Iterable[str]) -&gt; Iterator[int]</code>  给定一个字符串迭代器（比如一个python文件句柄），返回一个有延迟的(lazily)token ID生成器。这是为了那些我们不能直接加载进内存的大型文件准备的。  </p>
<p><code>def decode(self, ids: list[int]) -&gt; str</code> 把token IDs解码成text文本。  </p>
<p>同样地，写好了之后先接入<code>adapters.get_tokenizer</code>，然后<code>uv run pytest tests/test_tokenizer.py</code>；你需要通过所有测试。  </p>
<h4 id="Answer：-1"><a href="#Answer：-1" class="headerlink" title="Answer："></a>Answer：</h4><p>见<br><a target="_blank" rel="noopener" href="https://github.com/Zian-2/cs336_assignments_and_notes/blob/main/assignment1-basics/cs336_basics/tokenizer.py">https://github.com/Zian-2/cs336_assignments_and_notes/blob/main/assignment1-basics/cs336_basics/tokenizer.py</a>  ，<br>本节答案对应截止在# —2.6 Encoding &amp; Decoding—#下方的内容。    </p>
<p>windows上测试依旧出现问题。最好还是在linux上跑吧……<br>通过测试：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">============================= test session starts ==============================</span><br><span class="line">platform linux -- Python <span class="number">3.13</span><span class="number">.3</span>, pytest-<span class="number">8.4</span><span class="number">.1</span>, pluggy-<span class="number">1.6</span><span class="number">.0</span></span><br><span class="line">rootdir: /home/wangzian/Desktop/cs336_assignments_and_notes/assignment1-basics</span><br><span class="line">configfile: pyproject.toml</span><br><span class="line">plugins: jaxtyping-<span class="number">0.3</span><span class="number">.2</span></span><br><span class="line">collected <span class="number">25</span> items                                                             </span><br><span class="line"></span><br><span class="line">tests/test_tokenizer.py::test_roundtrip_empty PASSED</span><br><span class="line">tests/test_tokenizer.py::test_empty_matches_tiktoken PASSED</span><br><span class="line">tests/test_tokenizer.py::test_roundtrip_single_character PASSED</span><br><span class="line">tests/test_tokenizer.py::test_single_character_matches_tiktoken PASSED</span><br><span class="line">tests/test_tokenizer.py::test_roundtrip_single_unicode_character PASSED</span><br><span class="line">tests/test_tokenizer.py::test_single_unicode_character_matches_tiktoken PASSED</span><br><span class="line">tests/test_tokenizer.py::test_roundtrip_ascii_string PASSED</span><br><span class="line">tests/test_tokenizer.py::test_ascii_string_matches_tiktoken PASSED</span><br><span class="line">tests/test_tokenizer.py::test_roundtrip_unicode_string PASSED</span><br><span class="line">tests/test_tokenizer.py::test_unicode_string_matches_tiktoken PASSED</span><br><span class="line">tests/test_tokenizer.py::test_roundtrip_unicode_string_with_special_tokens PASSED</span><br><span class="line">tests/test_tokenizer.py::test_unicode_string_with_special_tokens_matches_tiktoken PASSED</span><br><span class="line">tests/test_tokenizer.py::test_overlapping_special_tokens PASSED</span><br><span class="line">tests/test_tokenizer.py::test_address_roundtrip PASSED</span><br><span class="line">tests/test_tokenizer.py::test_address_matches_tiktoken PASSED</span><br><span class="line">tests/test_tokenizer.py::test_german_roundtrip PASSED</span><br><span class="line">tests/test_tokenizer.py::test_german_matches_tiktoken PASSED</span><br><span class="line">tests/test_tokenizer.py::test_tinystories_sample_roundtrip PASSED</span><br><span class="line">tests/test_tokenizer.py::test_tinystories_matches_tiktoken PASSED</span><br><span class="line">tests/test_tokenizer.py::test_encode_special_token_trailing_newlines PASSED</span><br><span class="line">tests/test_tokenizer.py::test_encode_special_token_double_newline_non_whitespace PASSED</span><br><span class="line">tests/test_tokenizer.py::test_encode_iterable_tinystories_sample_roundtrip PASSED</span><br><span class="line">tests/test_tokenizer.py::test_encode_iterable_tinystories_matches_tiktoken PASSED</span><br><span class="line">tests/test_tokenizer.py::test_encode_iterable_memory_usage PASSED</span><br><span class="line">tests/test_tokenizer.py::test_encode_memory_usage XFAIL (Tokenizer.e...)</span><br><span class="line"></span><br><span class="line">======================== <span class="number">24</span> passed, <span class="number">1</span> xfailed <span class="keyword">in</span> <span class="number">5.99</span>s =========================</span><br></pre></td></tr></table></figure></p>
<p>linux虚拟机下测试时间5.99s。只要逻辑不要太离谱（比如直接遍历merge）基本时间上不会有太大问题。</p>
<h3 id="2-7-实验"><a href="#2-7-实验" class="headerlink" title="2.7 实验"></a>2.7 实验</h3><p>(a) 从 TinyStories 和 OpenWebText 中各随机抽取 10 份文档。使用你之前训练好的 TinyStories 分词器（词表大小 10K）和 OpenWebText 分词器（词表大小 32K），将这些抽样的文档编码为整数 ID。每个分词器的压缩比（字节/Token）是多少？</p>
<p>(b) 如果你用 TinyStories 的分词器去对 OpenWebText 的样本进行分词，会发生什么？比较其压缩比并（或）从定性角度描述发生的现象。</p>
<p>(c) 估算你的分词器的吞吐量（throughput)（例如：bytes/秒）。以此速度，分词整个Pile数据集（825GB 文本）需要多长时间？</p>
<p>(d) 使用你的 TinyStories 和 OpenWebText 分词器，将各自对应的训练集和开发集编码为整数 Token ID 序列。我们稍后将使用这些数据来训练语言模型。我们建议将这些 Token ID 序列序列化为 uint16 数据类型的 NumPy 数组。为什么选择 uint16 是一个合适的选择？</p>
<h4 id="Answer：-2"><a href="#Answer：-2" class="headerlink" title="Answer："></a>Answer：</h4><p>(a) Tiny 在 4.11左右， owt在4.42左右。可见owt三倍于Tiny的词表尺寸还是可以客观地提高压缩率。<br>(b) 压缩率在3.3左右。可见tiny的词表相对于owt的内容还是有比较大局限。<br>(c) 在Tiny_valid上验证，吞吐量: 5.5023 MB/s。预估分词 Pile (825GB): 42.65 小时。<br>(d)  1 无符号这一点和tokenID是相同的   2 数值范围到65536，比较适配词表大小。</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># 深度学习</a>
              <a href="/tags/cs336/" rel="tag"># cs336</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2026/01/21/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC/" rel="prev" title="矩阵求导理论：几种表示">
                  <i class="fa fa-angle-left"></i> 矩阵求导理论：几种表示
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2026/01/27/tokenizer.py/" rel="next" title="tokenizer.py">
                  tokenizer.py <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2026</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Zian Wang</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

<script src="/live2d-widget/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2d-widget/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2d-widget/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":200,"hOffset":20,"vOffset":0},"mobile":{"show":false},"react":{"opacityDefault":0.5,"opacityOnHover":1},"log":false});</script></body>

</html>
